{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import collections\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Treebank in Train and Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "random.seed(123)\n",
    "train_set, test_set = train_test_split(nltk_data,train_size= .95, test_size=0.05, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Reliance', 'NOUN'),\n",
       " ('acquired', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('7', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('UAL', 'NOUN'),\n",
       " ('stake', 'NOUN'),\n",
       " ('early', 'ADV'),\n",
       " ('this', 'DET'),\n",
       " ('year', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('average', 'ADJ'),\n",
       " ('cost', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('110', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('share', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('reduced', 'VERB'),\n",
       " ('its', 'PRON'),\n",
       " ('stake', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('4.7', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('after', 'ADP'),\n",
       " ('UAL', 'NOUN'),\n",
       " ('accepted', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('bid', 'NOUN'),\n",
       " ('at', 'ADP'),\n",
       " ('prices', 'NOUN'),\n",
       " ('higher', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('282', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('share', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Reliance', 'NOUN'),\n",
       " ('acquired', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('7', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('UAL', 'NOUN'),\n",
       " ('stake', 'NOUN'),\n",
       " ('early', 'ADV'),\n",
       " ('this', 'DET'),\n",
       " ('year', 'NOUN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [word for tup in train_set for word in tup]\n",
    "\n",
    "test_tagged_words = [word for tup in test_set for word in tup]\n",
    "\n",
    "train_tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95656\n"
     ]
    }
   ],
   "source": [
    "# list of all words\n",
    "train_words = [tags[0] for tags in train_tagged_words]\n",
    "test_words = [tags[0] for tags in test_tagged_words]\n",
    "print(len(train_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12102\n"
     ]
    }
   ],
   "source": [
    "# unique vocabulary\n",
    "v_train = set(train_words)\n",
    "v_test = set(test_words)\n",
    "print(len(v_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'82\",\n",
       " '*-101',\n",
       " '*-109',\n",
       " '*-144',\n",
       " '*-147',\n",
       " '*-150',\n",
       " '*-151',\n",
       " '*-155',\n",
       " '*-156',\n",
       " '*T*-104',\n",
       " '*T*-105',\n",
       " '*T*-143',\n",
       " '*T*-144',\n",
       " '*T*-161',\n",
       " '*T*-168',\n",
       " '*T*-184',\n",
       " '*T*-232',\n",
       " '*T*-249',\n",
       " '*T*-250',\n",
       " '115',\n",
       " '154,240,000',\n",
       " '158,666',\n",
       " '176.1',\n",
       " '1925',\n",
       " '1934',\n",
       " '20.07',\n",
       " '26,956',\n",
       " '3.43',\n",
       " '352.7',\n",
       " '35500.64',\n",
       " '51-year-old',\n",
       " '576',\n",
       " '6.53',\n",
       " '608,413',\n",
       " '62.625',\n",
       " '63.79',\n",
       " '692',\n",
       " '7.20',\n",
       " '7.84',\n",
       " '80.8',\n",
       " '81.8',\n",
       " '84-year-old',\n",
       " '960',\n",
       " '967,809',\n",
       " 'Alexander',\n",
       " 'Ariail',\n",
       " 'Assets',\n",
       " 'Bennett',\n",
       " 'Boeing',\n",
       " 'Buckhead',\n",
       " 'Carbide',\n",
       " 'Carnegie-Mellon',\n",
       " 'Carrier',\n",
       " 'Cartons',\n",
       " 'Cerf',\n",
       " 'Competes',\n",
       " 'Debt',\n",
       " 'Default',\n",
       " 'Destinations',\n",
       " 'Determining',\n",
       " 'Discos',\n",
       " 'Doerflinger',\n",
       " 'Drink',\n",
       " 'Dunn',\n",
       " 'Dynamics',\n",
       " 'Editorials',\n",
       " 'Emile',\n",
       " 'Foreigners',\n",
       " 'Fuentes',\n",
       " 'Graham',\n",
       " 'Green',\n",
       " 'Gringo',\n",
       " 'Hans',\n",
       " 'Helsinki',\n",
       " 'Henderson',\n",
       " 'Herald-American',\n",
       " 'Honolulu',\n",
       " 'Ian',\n",
       " 'Joni',\n",
       " 'Kelli',\n",
       " 'Kirkpatrick',\n",
       " 'Leningrad',\n",
       " 'Leon',\n",
       " 'Level',\n",
       " 'Lucille',\n",
       " 'Manila',\n",
       " 'McCabe',\n",
       " 'McFarlan',\n",
       " 'Mercedes',\n",
       " 'Metal',\n",
       " 'Mexican',\n",
       " 'Mostly',\n",
       " 'Mutchin',\n",
       " 'News-American',\n",
       " 'Orlando',\n",
       " 'Per-share',\n",
       " 'Performing',\n",
       " 'Phillip',\n",
       " 'Possibly',\n",
       " 'Rail',\n",
       " 'Regarded',\n",
       " 'Remember',\n",
       " 'Revolution',\n",
       " 'Rock',\n",
       " 'Sauternes',\n",
       " 'Schaefer',\n",
       " 'Schwab',\n",
       " 'Sherwin',\n",
       " 'Shortly',\n",
       " 'Sit',\n",
       " 'Skokie',\n",
       " 'Sonny',\n",
       " 'Squier',\n",
       " 'Subcontractors',\n",
       " 'Sumitomo',\n",
       " 'Terrace',\n",
       " 'Theodore',\n",
       " 'Troubled',\n",
       " 'Vice',\n",
       " 'Worksheets',\n",
       " 'Yasuda',\n",
       " 'abating',\n",
       " 'aces',\n",
       " 'acknowledge',\n",
       " 'adapting',\n",
       " 'adopt',\n",
       " 'afterwards',\n",
       " 'aids',\n",
       " 'amazingly',\n",
       " 'amended',\n",
       " 'anti-China',\n",
       " 'appropriate',\n",
       " 'assemble',\n",
       " 'assure',\n",
       " 'astronomical',\n",
       " 'authorizes',\n",
       " 'authorizing',\n",
       " 'automation',\n",
       " 'autos',\n",
       " 'avert',\n",
       " 'awfully',\n",
       " 'bars',\n",
       " 'blender',\n",
       " 'brand',\n",
       " 'broad-based',\n",
       " 'car-care',\n",
       " 'chairs',\n",
       " 'challenging',\n",
       " 'close-up',\n",
       " 'clothes',\n",
       " 'cocky',\n",
       " 'codified',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'communication',\n",
       " 'companion',\n",
       " 'complain',\n",
       " 'computer-aided',\n",
       " 'concedes',\n",
       " 'copied',\n",
       " 'cornerstones',\n",
       " 'counterattack',\n",
       " 'crashing',\n",
       " 'dancing',\n",
       " 'dawn',\n",
       " 'day-to-day',\n",
       " 'dealing',\n",
       " 'decisive',\n",
       " 'designated',\n",
       " 'destination',\n",
       " 'direct-investment',\n",
       " 'directionless',\n",
       " 'dirty',\n",
       " 'discontinuing',\n",
       " 'dislike',\n",
       " 'displays',\n",
       " 'distasteful',\n",
       " 'distributes',\n",
       " 'dominant',\n",
       " 'dominates',\n",
       " 'driver',\n",
       " 'earliest',\n",
       " 'echoed',\n",
       " 'eight-count',\n",
       " 'enable',\n",
       " 'enclosed',\n",
       " 'enjoyed',\n",
       " 'entering',\n",
       " 'equal-opportunity',\n",
       " 'erroneous',\n",
       " 'everybody',\n",
       " 'excited',\n",
       " 'exempt',\n",
       " 'fly',\n",
       " 'folded',\n",
       " 'forthcoming',\n",
       " 'gamut',\n",
       " 'garden-variety',\n",
       " 'genie',\n",
       " 'headcount-control',\n",
       " 'high-level',\n",
       " 'housewife',\n",
       " 'hurdles',\n",
       " 'indictment',\n",
       " 'inflationary',\n",
       " 'informally',\n",
       " 'infringed',\n",
       " 'infusion',\n",
       " 'insane',\n",
       " 'intelligent',\n",
       " 'invention',\n",
       " 'iota',\n",
       " 'jolts',\n",
       " 'kit',\n",
       " 'lapses',\n",
       " 'le',\n",
       " 'learning',\n",
       " 'leery',\n",
       " 'legislators',\n",
       " 'licensing',\n",
       " 'lifes',\n",
       " 'lighter',\n",
       " 'literature',\n",
       " 'livelihood',\n",
       " 'lookee-loos',\n",
       " 'loom',\n",
       " 'manipulate',\n",
       " 'materialized',\n",
       " 'mentioned',\n",
       " 'microphone',\n",
       " 'mid-1990s',\n",
       " 'ministers',\n",
       " 'most-likely-successor',\n",
       " 'mothers',\n",
       " 'newsworthy',\n",
       " 'nonetheless',\n",
       " 'one-fifth',\n",
       " 'onslaught',\n",
       " 'opinions',\n",
       " 'ordeal',\n",
       " 'ornamental',\n",
       " 'overlap',\n",
       " 'oversight',\n",
       " 'overstated',\n",
       " 'overused',\n",
       " 'partial',\n",
       " 'phase',\n",
       " 'plane',\n",
       " 'precedes',\n",
       " 'predicated',\n",
       " 'prescribe',\n",
       " 'princely',\n",
       " 'procurement',\n",
       " 'produces',\n",
       " 'productivity',\n",
       " 'psychiatrist',\n",
       " 'recall',\n",
       " 'recalling',\n",
       " 'recruited',\n",
       " 'redeeming',\n",
       " 'rendering',\n",
       " 'restricts',\n",
       " 'resume',\n",
       " 'retiring',\n",
       " 'seconds',\n",
       " 'self-esteem',\n",
       " 'shadows',\n",
       " 'shaping',\n",
       " 'shipyards',\n",
       " 'shrug',\n",
       " 'skepticism',\n",
       " 'skilled',\n",
       " 'slowdowns',\n",
       " 'smoothly',\n",
       " 'sometimes-tawdry',\n",
       " 'species',\n",
       " 'spectacular',\n",
       " 'spectacularly',\n",
       " 'speculate',\n",
       " 'sticker-shock',\n",
       " 'stirrings',\n",
       " 'stock-price',\n",
       " 'stream',\n",
       " 'striving',\n",
       " 'suburban',\n",
       " 'swift',\n",
       " 'talked',\n",
       " 'telephone-information',\n",
       " 'test-practice',\n",
       " 'thousand',\n",
       " 'tire-kickers',\n",
       " 'transporting',\n",
       " 'troop',\n",
       " 'truthful',\n",
       " 'tubes',\n",
       " 'twin-jet',\n",
       " 'undercut',\n",
       " 'unenticing',\n",
       " 'unpleasant',\n",
       " 'unpublished',\n",
       " 'unrealized',\n",
       " 'unwind',\n",
       " 'workforce',\n",
       " 'worsen',\n",
       " 'wrestling',\n",
       " 'yen-denominated'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the differnece in vocabulary of train and test\n",
    "(v_test.difference(v_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "There is a difference in the volcabularies of train and test set. Hence there will be cases on unkown words while tagging test dataset. We shall try following methods for unknown words\n",
    "\n",
    "<hr>\n",
    "\n",
    "1. Tag unkown words with mode of available tags.\n",
    "2. Apply Regex to find the closest tag from train set that can be aplied to unknwon words.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique tags\n",
    "T = set([tags[1] for tags in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max tags\n",
    "most_tag = collections.Counter([tags[1] for tags in train_tagged_words]).most_common(1)[0][0]\n",
    "most_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    # find all words where the give tag is available\n",
    "    tag_list = [i for i in train_bag if i[1] == tag]\n",
    "    # from tag_list find out where the given word is available\n",
    "    word_given_tag_list = [i[0] for i in tag_list if i[0] == word]\n",
    "    \n",
    "    count_tags = len(tag_list)\n",
    "    count_words_given_tag = len(word_given_tag_list)\n",
    "    \n",
    "    return(count_words_given_tag/count_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    # find all tags\n",
    "    all_tags = [i[1] for i in train_bag]\n",
    "    \n",
    "    # from all tags find all t1 tages\n",
    "    count_t1 = len([i for i in all_tags if i == t1])\n",
    "    \n",
    "    # from all tags find where t1 is followed by t2\n",
    "    count_t2_t1 = 0\n",
    "    \n",
    "    for index in range(len(all_tags)-1):\n",
    "        if all_tags[index]==t1 and all_tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "       \n",
    "    return(count_t2_t1/count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transition Probability Matrix of all combinations of tags t2 given tags t1\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "\n",
    "# column is t2, row is t1\n",
    "\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)):\n",
    "        tags_matrix[i,j] = t2_given_t1(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.71592802e-02, 6.56814431e-04, 1.06732352e-02, 2.08538584e-02,\n",
       "        4.92610829e-03, 6.99507415e-01, 7.79967159e-02, 2.08538584e-02,\n",
       "        1.55993430e-02, 6.46962225e-02, 1.23152705e-02, 4.76190494e-03],\n",
       "       [7.18146712e-02, 8.10810830e-03, 1.15830116e-02, 9.34362933e-02,\n",
       "        9.65250935e-03, 2.08880305e-01, 2.35521235e-02, 6.17760606e-03,\n",
       "        5.01930481e-03, 4.09266427e-02, 4.86872584e-01, 3.39768343e-02],\n",
       "       [8.56954530e-02, 1.64798945e-02, 1.97758735e-03, 1.41727095e-02,\n",
       "        1.02834545e-01, 2.45550424e-01, 2.07646675e-02, 5.63612394e-02,\n",
       "        1.97758735e-03, 4.28477265e-02, 4.01450217e-01, 9.88793653e-03],\n",
       "       [1.76386461e-02, 5.49817272e-02, 1.82583824e-01, 7.51628801e-02,\n",
       "        5.51406331e-02, 6.13379963e-02, 1.44287303e-01, 2.70141428e-03,\n",
       "        1.03289373e-02, 1.64150640e-01, 2.06102014e-01, 2.55839825e-02],\n",
       "       [2.05684006e-01, 3.49229295e-03, 2.40847789e-04, 4.57610786e-02,\n",
       "        5.41907502e-03, 6.38246655e-01, 9.27263964e-03, 2.16763001e-02,\n",
       "        4.81695577e-04, 1.80635843e-02, 3.87764946e-02, 1.28853563e-02],\n",
       "       [1.20925149e-02, 4.73502092e-03, 4.34165001e-02, 2.92114373e-02,\n",
       "        1.31852124e-02, 2.63995618e-01, 1.77381173e-01, 9.57931206e-03,\n",
       "        4.26151901e-02, 2.39919871e-01, 1.46712810e-01, 1.71553455e-02],\n",
       "       [1.05986364e-01, 6.81721345e-02, 1.49126549e-03, 3.47251818e-02,\n",
       "        3.25308919e-01, 3.22113335e-01, 1.70430336e-02, 6.30592257e-02,\n",
       "        8.52151657e-04, 3.96250524e-02, 8.62803590e-03, 1.29953129e-02],\n",
       "       [3.26409489e-02, 1.48367952e-03, 2.75964383e-02, 2.09792286e-01,\n",
       "        3.26409494e-03, 3.54599416e-01, 3.50148380e-02, 1.84866473e-01,\n",
       "        1.39465872e-02, 1.16617210e-01, 1.72106829e-02, 2.96735903e-03],\n",
       "       [1.17180206e-01, 5.74229695e-02, 4.66853427e-03, 8.87021516e-03,\n",
       "        1.19514473e-01, 3.55275452e-01, 5.22875823e-02, 4.10831012e-02,\n",
       "        4.66853409e-04, 3.45471539e-02, 1.55462191e-01, 5.32212891e-02],\n",
       "       [4.52789515e-02, 6.59419671e-02, 2.42565805e-03, 2.73111127e-02,\n",
       "        1.72940433e-01, 2.22621500e-01, 9.12766159e-02, 8.12146291e-02,\n",
       "        5.75869195e-02, 9.28038806e-02, 8.82220790e-02, 5.22864088e-02],\n",
       "       [6.54947087e-02, 3.58587429e-02, 3.13472301e-02, 2.17952713e-01,\n",
       "        1.34489730e-01, 1.10609829e-01, 9.08525214e-02, 2.28687003e-02,\n",
       "        5.44492854e-03, 3.47697586e-02, 1.68403864e-01, 8.19072798e-02],\n",
       "       [1.27206132e-01, 1.56510156e-02, 1.43190147e-02, 2.26440225e-02,\n",
       "        6.92640692e-02, 3.13020311e-02, 1.19880117e-01, 3.16350311e-02,\n",
       "        7.32600736e-03, 1.37196139e-01, 3.44988346e-01, 7.85880759e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>.</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.067159</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.077997</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.064696</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.071815</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.093436</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.208880</td>\n",
       "      <td>0.023552</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.040927</td>\n",
       "      <td>0.486873</td>\n",
       "      <td>0.033977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.085695</td>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.014173</td>\n",
       "      <td>0.102835</td>\n",
       "      <td>0.245550</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.056361</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.042848</td>\n",
       "      <td>0.401450</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.017639</td>\n",
       "      <td>0.054982</td>\n",
       "      <td>0.182584</td>\n",
       "      <td>0.075163</td>\n",
       "      <td>0.055141</td>\n",
       "      <td>0.061338</td>\n",
       "      <td>0.144287</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.164151</td>\n",
       "      <td>0.206102</td>\n",
       "      <td>0.025584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.205684</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.045761</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.638247</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.021676</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.038776</td>\n",
       "      <td>0.012885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.043417</td>\n",
       "      <td>0.029211</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.263996</td>\n",
       "      <td>0.177381</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>0.042615</td>\n",
       "      <td>0.239920</td>\n",
       "      <td>0.146713</td>\n",
       "      <td>0.017155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.105986</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.034725</td>\n",
       "      <td>0.325309</td>\n",
       "      <td>0.322113</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>0.063059</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.012995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.027596</td>\n",
       "      <td>0.209792</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.354599</td>\n",
       "      <td>0.035015</td>\n",
       "      <td>0.184866</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.116617</td>\n",
       "      <td>0.017211</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.117180</td>\n",
       "      <td>0.057423</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.119514</td>\n",
       "      <td>0.355275</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.041083</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.034547</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.053221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.045279</td>\n",
       "      <td>0.065942</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.027311</td>\n",
       "      <td>0.172940</td>\n",
       "      <td>0.222622</td>\n",
       "      <td>0.091277</td>\n",
       "      <td>0.081215</td>\n",
       "      <td>0.057587</td>\n",
       "      <td>0.092804</td>\n",
       "      <td>0.088222</td>\n",
       "      <td>0.052286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.065495</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.217953</td>\n",
       "      <td>0.134490</td>\n",
       "      <td>0.110610</td>\n",
       "      <td>0.090853</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.168404</td>\n",
       "      <td>0.081907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.127206</td>\n",
       "      <td>0.015651</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>0.031302</td>\n",
       "      <td>0.119880</td>\n",
       "      <td>0.031635</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.137196</td>\n",
       "      <td>0.344988</td>\n",
       "      <td>0.078588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADJ      PRON       PRT         X       DET      NOUN       ADP  \\\n",
       "ADJ   0.067159  0.000657  0.010673  0.020854  0.004926  0.699507  0.077997   \n",
       "PRON  0.071815  0.008108  0.011583  0.093436  0.009653  0.208880  0.023552   \n",
       "PRT   0.085695  0.016480  0.001978  0.014173  0.102835  0.245550  0.020765   \n",
       "X     0.017639  0.054982  0.182584  0.075163  0.055141  0.061338  0.144287   \n",
       "DET   0.205684  0.003492  0.000241  0.045761  0.005419  0.638247  0.009273   \n",
       "NOUN  0.012093  0.004735  0.043417  0.029211  0.013185  0.263996  0.177381   \n",
       "ADP   0.105986  0.068172  0.001491  0.034725  0.325309  0.322113  0.017043   \n",
       "NUM   0.032641  0.001484  0.027596  0.209792  0.003264  0.354599  0.035015   \n",
       "CONJ  0.117180  0.057423  0.004669  0.008870  0.119514  0.355275  0.052288   \n",
       ".     0.045279  0.065942  0.002426  0.027311  0.172940  0.222622  0.091277   \n",
       "VERB  0.065495  0.035859  0.031347  0.217953  0.134490  0.110610  0.090853   \n",
       "ADV   0.127206  0.015651  0.014319  0.022644  0.069264  0.031302  0.119880   \n",
       "\n",
       "           NUM      CONJ         .      VERB       ADV  \n",
       "ADJ   0.020854  0.015599  0.064696  0.012315  0.004762  \n",
       "PRON  0.006178  0.005019  0.040927  0.486873  0.033977  \n",
       "PRT   0.056361  0.001978  0.042848  0.401450  0.009888  \n",
       "X     0.002701  0.010329  0.164151  0.206102  0.025584  \n",
       "DET   0.021676  0.000482  0.018064  0.038776  0.012885  \n",
       "NOUN  0.009579  0.042615  0.239920  0.146713  0.017155  \n",
       "ADP   0.063059  0.000852  0.039625  0.008628  0.012995  \n",
       "NUM   0.184866  0.013947  0.116617  0.017211  0.002967  \n",
       "CONJ  0.041083  0.000467  0.034547  0.155462  0.053221  \n",
       ".     0.081215  0.057587  0.092804  0.088222  0.052286  \n",
       "VERB  0.022869  0.005445  0.034770  0.168404  0.081907  \n",
       "ADV   0.031635  0.007326  0.137196  0.344988  0.078588  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Matrix to Data Frame for easy understanding\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    # Find all unique tags\n",
    "    T = list(set([i[1] for i in train_bag]))\n",
    "    \n",
    "    # Find likelyhood of a word having all types of tags\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given word/observation\n",
    "        p = []\n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0: # if the word is the first word in the sentence\n",
    "                transition_p = tags_df.loc[\".\",tag]\n",
    "            elif key == len(words): # if the word is the last word in the sentence\n",
    "                transition_p = tags_df.loc[tag,\".\"]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1],tag]\n",
    "            \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p\n",
    "            \n",
    "            p.append(state_probability)\n",
    "        \n",
    "        # Find the tag with maximum state probability\n",
    "        pmax = max(p)\n",
    "        \n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    \n",
    "    return list(zip(words, state))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untagged test set\n",
    "test_untagged_words = [i[0] for i in test_tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_untagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  513.8241579532623\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "matched = [i for i,j in zip(tagged_seq,test_tagged_words) if i == j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205179282868526"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = len(matched)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched= [i for i,j in zip(tagged_seq,test_tagged_words) if i != j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0794820717131474"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %Unmatched records\n",
    "failure = len(unmatched)/len(tagged_seq)\n",
    "failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Worksheets', 'ADJ'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('test-practice', 'ADJ'),\n",
       " ('kit', 'ADJ'),\n",
       " ('called', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('Learning', 'NOUN'),\n",
       " ('Materials', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('sold', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('schools', 'NOUN'),\n",
       " ('across', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('country', 'NOUN'),\n",
       " ('by', 'ADP'),\n",
       " ('Macmillan\\\\/McGraw-Hill', 'NOUN'),\n",
       " ('School', 'NOUN'),\n",
       " ('Publishing', 'NOUN'),\n",
       " ('Co.', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('contain', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('same', 'ADJ'),\n",
       " ('questions', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Government', 'NOUN'),\n",
       " ('officials', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('especially', 'ADV'),\n",
       " ('in', 'ADP'),\n",
       " ('Japan', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('probably', 'ADV'),\n",
       " ('would', 'VERB'),\n",
       " ('resist', 'VERB'),\n",
       " ('any', 'DET'),\n",
       " ('onslaught', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('program', 'NOUN'),\n",
       " ('trading', 'NOUN'),\n",
       " ('by', 'ADP'),\n",
       " ('players', 'NOUN'),\n",
       " ('trying', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('shrug', 'ADJ'),\n",
       " ('off', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('furor', 'NOUN'),\n",
       " ('over', 'ADP'),\n",
       " ('their', 'PRON'),\n",
       " ('activities', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('marching', 'VERB'),\n",
       " ('abroad', 'ADV'),\n",
       " ('with', 'ADP'),\n",
       " ('their', 'PRON'),\n",
       " ('business', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Ms.', 'NOUN'),\n",
       " ('Kirkpatrick', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('Journal', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('deputy', 'NOUN'),\n",
       " ('editorial', 'NOUN'),\n",
       " ('features', 'NOUN'),\n",
       " ('editor', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('worked', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Tokyo', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('three', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DET'),\n",
       " ('buyer', 'NOUN'),\n",
       " ('who', 'PRON'),\n",
       " ('*T*-58', 'X'),\n",
       " ('chooses', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('fly', 'ADJ'),\n",
       " ('to', 'PRT'),\n",
       " ('his', 'PRON'),\n",
       " ('destination', 'ADJ'),\n",
       " ('must', 'VERB'),\n",
       " ('pay', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('his', 'PRON'),\n",
       " ('own', 'ADJ'),\n",
       " ('ticket', 'NOUN'),\n",
       " ('but', 'CONJ'),\n",
       " ('gets', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('companion', 'ADJ'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('ticket', 'NOUN'),\n",
       " ('free', 'ADJ'),\n",
       " ('if', 'ADP'),\n",
       " ('they', 'PRON'),\n",
       " ('fly', 'ADJ'),\n",
       " ('on', 'ADP'),\n",
       " ('United', 'NOUN'),\n",
       " ('Airlines', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('The', 'DET'),\n",
       " ('sustained', 'VERB'),\n",
       " ('level', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('confidence', 'NOUN'),\n",
       " ('can', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('attributed', 'VERB'),\n",
       " ('*-3', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('the', 'DET'),\n",
       " ('continued', 'VERB'),\n",
       " ('favorable', 'ADJ'),\n",
       " ('circumstances', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-1', 'X'),\n",
       " ('affect', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('consumer', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('day-to-day', 'ADJ'),\n",
       " ('economic', 'ADJ'),\n",
       " ('life', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('said', 'VERB'),\n",
       " ('*T*-2', 'X'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Linden', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('It', 'PRON'),\n",
       " (\"'s\", 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('if', 'ADP'),\n",
       " ('France', 'NOUN'),\n",
       " ('decided', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('give', 'VERB'),\n",
       " ('only', 'ADV'),\n",
       " ('French', 'ADJ'),\n",
       " ('history', 'NOUN'),\n",
       " ('questions', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('students', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('European', 'ADJ'),\n",
       " ('history', 'NOUN'),\n",
       " ('class', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('when', 'ADV'),\n",
       " ('everybody', 'ADJ'),\n",
       " ('aces', 'ADJ'),\n",
       " ('the', 'DET'),\n",
       " ('test', 'NOUN'),\n",
       " ('*T*-3', 'X'),\n",
       " (',', '.'),\n",
       " ('they', 'PRON'),\n",
       " ('say', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('their', 'PRON'),\n",
       " ('kids', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('good', 'ADJ'),\n",
       " ('in', 'ADP'),\n",
       " ('European', 'ADJ'),\n",
       " ('history', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('says', 'VERB'),\n",
       " ('*T*-2', 'X'),\n",
       " ('John', 'NOUN'),\n",
       " ('Cannell', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('an', 'DET'),\n",
       " ('Albuquerque', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('N.M.', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('psychiatrist', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('founder', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('educational', 'ADJ'),\n",
       " ('research', 'NOUN'),\n",
       " ('organization', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Friends', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('Education', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-105', 'ADJ'),\n",
       " ('has', 'VERB'),\n",
       " ('studied', 'VERB'),\n",
       " ('standardized', 'ADJ'),\n",
       " ('testing', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('In', 'ADP'),\n",
       " ('major', 'ADJ'),\n",
       " ('market', 'NOUN'),\n",
       " ('activity', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('Phillip', 'ADJ'),\n",
       " ('Riese', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('an', 'DET'),\n",
       " ('American', 'ADJ'),\n",
       " ('Express', 'NOUN'),\n",
       " ('executive', 'NOUN'),\n",
       " ('vice', 'NOUN'),\n",
       " ('president', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('says', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('the', 'DET'),\n",
       " ('promotion', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('Buick', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('his', 'PRON'),\n",
       " ('company', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('first', 'ADJ'),\n",
       " ('with', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('auto', 'NOUN'),\n",
       " ('maker', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('``', '.'),\n",
       " ('hopefully', 'ADV'),\n",
       " ('-LCB-', '.'),\n",
       " ('will', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('-RCB-', '.'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('many', 'ADJ'),\n",
       " (\"''\", '.'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('company', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('effort', 'NOUN'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('promote', 'VERB'),\n",
       " ('its', 'PRON'),\n",
       " ('green', 'ADJ'),\n",
       " ('card', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('``', '.'),\n",
       " ('the', 'DET'),\n",
       " ('total', 'ADJ'),\n",
       " ('car-care', 'ADJ'),\n",
       " ('card', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('--', '.'),\n",
       " ('$', '.'),\n",
       " ('10', 'NUM'),\n",
       " ('billion', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('of', 'ADP'),\n",
       " ('10-year', 'ADJ'),\n",
       " ('notes', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('0', 'X'),\n",
       " ('*T*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('auctioned', 'VERB'),\n",
       " ('*-109', 'ADJ'),\n",
       " ('Wednesday', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('to', 'PRT'),\n",
       " ('mature', 'VERB'),\n",
       " ('Nov.', 'NOUN'),\n",
       " ('15', 'NUM'),\n",
       " (',', '.'),\n",
       " ('1999', 'NUM'),\n",
       " ('.', '.'),\n",
       " ('Not', 'ADV'),\n",
       " ('included', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('most-likely-successor', 'ADJ'),\n",
       " ('list', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('Joni', 'ADJ'),\n",
       " ('Evans', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('recruited', 'ADJ'),\n",
       " ('*', 'X'),\n",
       " ('two', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('ago', 'ADP'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('publisher', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('adult', 'NOUN'),\n",
       " ('trade', 'NOUN'),\n",
       " ('books', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('Random', 'NOUN'),\n",
       " ('House', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('Sonny', 'ADJ'),\n",
       " ('Mehta', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('president', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('prestigious', 'ADJ'),\n",
       " ('Alfred', 'NOUN'),\n",
       " ('A.', 'NOUN'),\n",
       " ('Knopf', 'NOUN'),\n",
       " ('unit', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Dan', 'NOUN'),\n",
       " ('Droz', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('leader', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Carnegie-Mellon', 'ADJ'),\n",
       " ('group', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('sees', 'VERB'),\n",
       " ('benefits', 'NOUN'),\n",
       " ('all', 'DET'),\n",
       " ('around', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Bush', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('he', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('like', 'ADP'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('able', 'ADJ'),\n",
       " ('*-2', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('use', 'VERB'),\n",
       " ('this', 'DET'),\n",
       " ('procedure', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Stocks', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('Volume', 'NOUN'),\n",
       " ('154,240,000', 'ADJ'),\n",
       " ('shares', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CONJ'),\n",
       " ('then', 'ADV'),\n",
       " ('this', 'DET'),\n",
       " ('commercial', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('produced', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('Bob', 'NOUN'),\n",
       " ('Squier', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('gets', 'VERB'),\n",
       " ('down', 'ADV'),\n",
       " ('to', 'PRT'),\n",
       " ('its', 'PRON'),\n",
       " ('own', 'ADJ'),\n",
       " ('mean', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('dirty', 'ADJ'),\n",
       " ('business', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Indeed', 'ADV'),\n",
       " (',', '.'),\n",
       " ('Judge', 'NOUN'),\n",
       " (\"O'Brien\", 'NOUN'),\n",
       " ('ruled', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('``', '.'),\n",
       " ('it', 'PRON'),\n",
       " ('*EXP*-1', 'X'),\n",
       " ('would', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('easy', 'ADJ'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('conclude', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('USIA', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('position', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('`', '.'),\n",
       " ('inappropriate', 'ADJ'),\n",
       " ('or', 'CONJ'),\n",
       " ('even', 'ADV'),\n",
       " ('stupid', 'ADJ'),\n",
       " (',', '.'),\n",
       " (\"'\", '.'),\n",
       " (\"''\", '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('it', 'PRON'),\n",
       " (\"'s\", 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('law', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('acquired', 'VERB'),\n",
       " ('Thomas', 'NOUN'),\n",
       " ('Edison', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('microphone', 'ADJ'),\n",
       " ('patent', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('then', 'ADV'),\n",
       " ('immediately', 'ADV'),\n",
       " ('sued', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('Bell', 'NOUN'),\n",
       " ('Co.', 'NOUN'),\n",
       " ('*-1', 'X'),\n",
       " ('claiming', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('microphone', 'ADJ'),\n",
       " ('invented', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('my', 'PRON'),\n",
       " ('grandfather', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Emile', 'ADJ'),\n",
       " ('Berliner', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-2', 'X'),\n",
       " ('had', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('sold', 'VERB'),\n",
       " ('*-144', 'ADJ'),\n",
       " ('to', 'PRT'),\n",
       " ('Bell', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('princely', 'ADJ'),\n",
       " ('$', '.'),\n",
       " ('50,000', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " (',', '.'),\n",
       " ('infringed', 'ADJ'),\n",
       " ('upon', 'ADP'),\n",
       " ('Western', 'ADJ'),\n",
       " ('Union', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('Edison', 'NOUN'),\n",
       " ('patent', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Dinkins', 'NOUN'),\n",
       " ('did', 'VERB'),\n",
       " ('fail', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('file', 'VERB'),\n",
       " ('his', 'PRON'),\n",
       " ('income', 'NOUN'),\n",
       " ('taxes', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('four', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('he', 'PRON'),\n",
       " ('insists', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('he', 'PRON'),\n",
       " ('voluntarily', 'ADV'),\n",
       " ('admitted', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('``', '.'),\n",
       " ('oversight', 'ADJ'),\n",
       " (\"''\", '.'),\n",
       " ('when', 'ADV'),\n",
       " ('he', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('being', 'VERB'),\n",
       " ('considered', 'VERB'),\n",
       " ('*-2', 'X'),\n",
       " ('for', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('city', 'NOUN'),\n",
       " ('job', 'NOUN'),\n",
       " ('*T*-3', 'X'),\n",
       " ('.', '.'),\n",
       " ('Per-share', 'ADJ'),\n",
       " ('net', 'ADJ'),\n",
       " ('rose', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('7.84', 'ADJ'),\n",
       " ('yen', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('6.53', 'ADJ'),\n",
       " ('yen', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('An', 'DET'),\n",
       " ('attempted', 'VERB'),\n",
       " ('buy-out', 'NOUN'),\n",
       " ('led', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('John', 'NOUN'),\n",
       " ('J.', 'NOUN'),\n",
       " ('McCabe', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('chief', 'NOUN'),\n",
       " ('operating', 'VERB'),\n",
       " ('officer', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('never', 'ADV'),\n",
       " ('materialized', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('stream', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('what', 'PRON'),\n",
       " ('one', 'NUM'),\n",
       " ('staff', 'NOUN'),\n",
       " ('member', 'NOUN'),\n",
       " ('dismissed', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('as', 'ADP'),\n",
       " ('``', '.'),\n",
       " ('tire-kickers', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('lookee-loos', 'ADJ'),\n",
       " (\"''\", '.'),\n",
       " ('had', 'VERB'),\n",
       " ('filed', 'VERB'),\n",
       " ('through', 'ADP'),\n",
       " ('since', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Although', 'ADP'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('corn', 'NOUN'),\n",
       " ('stockpiles', 'NOUN'),\n",
       " ('shrank', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('roughly', 'ADV'),\n",
       " ('half', 'DET'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('wake', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('drought', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('Agriculture', 'NOUN'),\n",
       " ('Department', 'NOUN'),\n",
       " ('projects', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('nearly', 'ADV'),\n",
       " ('one-fifth', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('harvest', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('still', 'ADV'),\n",
       " ('be', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('storage', 'NOUN'),\n",
       " ('before', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('1990', 'NUM'),\n",
       " ('corn', 'NOUN'),\n",
       " ('harvest', 'NOUN'),\n",
       " ('begins', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('Lucille', 'ADJ'),\n",
       " ('Gorman', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('an', 'DET'),\n",
       " ('84-year-old', 'ADJ'),\n",
       " ('Chicago', 'NOUN'),\n",
       " ('housewife', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('has', 'VERB'),\n",
       " ('become', 'VERB'),\n",
       " ('amazingly', 'ADJ'),\n",
       " ('immune', 'ADJ'),\n",
       " ('to', 'PRT'),\n",
       " ('stock-market', 'NOUN'),\n",
       " ('jolts', 'ADJ'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('others', 'NOUN'),\n",
       " ('here', 'ADV'),\n",
       " ('today', 'NOUN'),\n",
       " ('live', 'VERB'),\n",
       " ('elsewhere', 'ADV'),\n",
       " ('.', '.'),\n",
       " ('But', 'CONJ'),\n",
       " ('Columbia', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('good', 'ADJ'),\n",
       " ('bank', 'NOUN'),\n",
       " ('would', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('regulated', 'VERB'),\n",
       " ('thrift', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('while', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('bad', 'ADJ'),\n",
       " ('bank', 'NOUN'),\n",
       " ('would', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('private', 'ADJ'),\n",
       " ('investment', 'NOUN'),\n",
       " ('company', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('holding', 'VERB'),\n",
       " ('some', 'DET'),\n",
       " ('of', 'ADP'),\n",
       " ('Columbia', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('junk', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('real', 'ADJ'),\n",
       " ('estate', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('equity', 'NOUN'),\n",
       " ('investments', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('forthcoming', 'ADJ'),\n",
       " ('maturity', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('November', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('10-year', 'ADJ'),\n",
       " ('Japanese', 'ADJ'),\n",
       " ('government', 'NOUN'),\n",
       " ('yen-denominated', 'ADJ'),\n",
       " ('bond', 'NOUN'),\n",
       " ('issue', 'NOUN'),\n",
       " ('valued', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('at', 'ADP'),\n",
       " ('about', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('16', 'NUM'),\n",
       " ('billion', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('has', 'VERB'),\n",
       " ('prompted', 'VERB'),\n",
       " ('speculation', 'NOUN'),\n",
       " ('*ICH*-2', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('market', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('investors', 'NOUN'),\n",
       " ('redeeming', 'ADJ'),\n",
       " ('the', 'DET'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('diversify', 'VERB'),\n",
       " ('into', 'ADP'),\n",
       " ('dollar-denominated', 'ADJ'),\n",
       " ('instruments', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('according', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Madison', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Big', 'NOUN'),\n",
       " ('Board', 'NOUN'),\n",
       " ('volume', 'NOUN'),\n",
       " ('amounted', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('154,240,000', 'ADJ'),\n",
       " ('shares', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('down', 'ADV'),\n",
       " ('from', 'ADP'),\n",
       " ('176.1', 'ADJ'),\n",
       " ('million', 'NUM'),\n",
       " ('Tuesday', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Second', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('it', 'PRON'),\n",
       " ('can', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('used', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('unwind', 'ADJ'),\n",
       " ('positions', 'NOUN'),\n",
       " ('before', 'ADP'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('trading', 'NOUN'),\n",
       " ('begins', 'VERB'),\n",
       " (',', '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('at', 'ADP'),\n",
       " ('prices', 'NOUN'),\n",
       " ('pegged', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('the', 'DET'),\n",
       " ('previous', 'ADJ'),\n",
       " ('session', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('Big', 'NOUN'),\n",
       " ('Board', 'NOUN'),\n",
       " ('close', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('Chateau', 'NOUN'),\n",
       " ('Yquem', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('leading', 'ADJ'),\n",
       " ('Sauternes', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('now', 'ADV'),\n",
       " ('goes', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('well', 'ADV'),\n",
       " ('over', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('100', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('bottle', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('lighter', 'ADJ'),\n",
       " ('vintage', 'NOUN'),\n",
       " ('like', 'ADP'),\n",
       " ('1984', 'NUM'),\n",
       " (';', '.'),\n",
       " ('the', 'DET'),\n",
       " ('spectacularly', 'ADJ'),\n",
       " ('rich', 'ADJ'),\n",
       " ('1983', 'NUM'),\n",
       " ('runs', 'VERB'),\n",
       " ('$', '.'),\n",
       " ('179', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('.', '.'),\n",
       " ('A', 'DET'),\n",
       " ('telephone-information', 'ADJ'),\n",
       " ('operator', 'NOUN'),\n",
       " ('had', 'VERB'),\n",
       " ('no', 'DET'),\n",
       " ('listing', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('either', 'DET'),\n",
       " ('party', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('$', '.'),\n",
       " ('80.8', 'ADJ'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('of', 'ADP'),\n",
       " ('single-family', 'ADJ'),\n",
       " ('program', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('1989', 'NUM'),\n",
       " ('fourth', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('fifth', 'ADJ'),\n",
       " ('series', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('tentatively', 'ADV'),\n",
       " ('priced', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('Merrill', 'NOUN'),\n",
       " ('Lynch', 'NOUN'),\n",
       " ('Capital', 'NOUN'),\n",
       " ('Markets', 'NOUN'),\n",
       " ('group', 'NOUN'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('yield', 'VERB'),\n",
       " ('from', 'ADP'),\n",
       " ('6.25', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('1992', 'NUM'),\n",
       " ('for', 'ADP'),\n",
       " ('fourth', 'ADJ'),\n",
       " ('series', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('7.74', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2029', 'NUM'),\n",
       " ('for', 'ADP'),\n",
       " ('fifth', 'ADJ'),\n",
       " ('series', 'NOUN'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DET'),\n",
       " ('being', 'VERB'),\n",
       " ('Britain', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('no', 'DET'),\n",
       " ('woman', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('filed', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('equal-opportunity', 'ADJ'),\n",
       " ('suit', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('extent', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('problem', 'NOUN'),\n",
       " ('surfaced', 'VERB'),\n",
       " ('this', 'DET'),\n",
       " ('summer', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('series', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('letters', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('``', '.'),\n",
       " ('The', 'DET'),\n",
       " ('Ringing', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('a', 'DET'),\n",
       " ('weekly', 'ADJ'),\n",
       " ('newspaper', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('ringers', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('She', 'PRON'),\n",
       " ('just', 'ADV'),\n",
       " ('never', 'ADV'),\n",
       " ('gave', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('up', 'ADV'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('says', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('Mary', 'NOUN'),\n",
       " ('Marchand', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Mary', 'NOUN'),\n",
       " ('Beth', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('mother', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('economists', 'NOUN'),\n",
       " ('forecast', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('0.1', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('rise', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('unemployment', 'NOUN'),\n",
       " ('rate', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('5.4', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('Coleman', 'NOUN'),\n",
       " ('counterattack', 'ADJ'),\n",
       " ('featured', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('close-up', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('young', 'ADJ'),\n",
       " ('woman', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('shadows', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('ad', 'NOUN'),\n",
       " ('suggested', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('she', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('recalling', 'ADJ'),\n",
       " ('an', 'DET'),\n",
       " ('unpleasant', 'ADJ'),\n",
       " ('courtroom', 'NOUN'),\n",
       " ('ordeal', 'ADJ'),\n",
       " ('.', '.'),\n",
       " ('Waertsilae', 'NOUN'),\n",
       " ('Marine', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('biggest', 'ADJ'),\n",
       " ('creditor', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('Miami-based', 'ADJ'),\n",
       " ('Carnival', 'NOUN'),\n",
       " ('Cruise', 'NOUN'),\n",
       " ('Lines', 'NOUN'),\n",
       " ('Inc', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('scammers', 'NOUN'),\n",
       " ('themselves', 'PRON'),\n",
       " ('were', 'VERB'),\n",
       " ('garden-variety', 'ADJ'),\n",
       " ('low', 'ADJ'),\n",
       " ('lifes', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('conspicuous', 'ADJ'),\n",
       " ('consumers', 'NOUN'),\n",
       " ('who', 'PRON'),\n",
       " ('*T*-1', 'X'),\n",
       " ('wanted', 'VERB'),\n",
       " ('big', 'ADJ'),\n",
       " ('houses', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Mercedes', 'ADJ'),\n",
       " ('cars', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('beautiful', 'ADJ'),\n",
       " ('women', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('expensive', 'ADJ'),\n",
       " ('clothes', 'ADJ'),\n",
       " ('.', '.'),\n",
       " ('Some', 'DET'),\n",
       " ('fellow', 'ADJ'),\n",
       " ('teachers', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('however', 'ADV'),\n",
       " (',', '.'),\n",
       " ('viewed', 'VERB'),\n",
       " ('Mrs.', 'NOUN'),\n",
       " ('Yeargin', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('cocky', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('too', 'ADV'),\n",
       " ('yielding', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('students', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Your', 'PRON'),\n",
       " ('Oct.', 'NOUN'),\n",
       " ('13', 'NUM'),\n",
       " ...]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "It can be noticed, lot of words are not predicted correctly. Like Worksheets etc are given the defauy tag of ADJ. Also, numeric fields are marked as default ADJ too. It is further noticed that the defaults are marked as ADJ for the unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Tagging unknow with mode of know tags from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_model1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    # Find all unique tags\n",
    "    T = list(set([i[1] for i in train_bag]))\n",
    "    \n",
    "    # Find likelyhood of a word having all types of tags\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given word/observation\n",
    "        p = []\n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0: # if the word is the first word in the sentence\n",
    "                transition_p = tags_df.loc[\".\",tag]\n",
    "            elif key == len(words): # if the word is the last word in the sentence\n",
    "                transition_p = tags_df.loc[tag,\".\"]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1],tag]\n",
    "            \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p\n",
    "            \n",
    "            p.append(state_probability)\n",
    "        \n",
    "        # Find the tag with maximum state probability\n",
    "        pmax = max(p)\n",
    "        \n",
    "        # For unknown words the state probability will be zero\n",
    "        if pmax == 0:\n",
    "            state.append(most_tag)\n",
    "        else:\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "    \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq_model1 = Viterbi_model1(test_untagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  516.9418249130249\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "matched_model1 = [i for i,j in zip(tagged_seq_model1,test_tagged_words) if i == j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408366533864542"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model1 = len(matched_model1)/len(tagged_seq_model1)\n",
    "accuracy_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Tagging unknown with using Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_model2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    state_bk = []\n",
    "    # Find all unique tags\n",
    "    T = list(set([i[1] for i in train_bag]))\n",
    "    \n",
    "    # Find likelyhood of a word having all types of tags\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given word/observation\n",
    "        p = []\n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0: # if the word is the first word in the sentence\n",
    "                transition_p = tags_df.loc[\".\",tag]\n",
    "            elif key == len(words): # if the word is the last word in the sentence\n",
    "                transition_p = tags_df.loc[tag,\".\"]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1],tag]\n",
    "            \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)\n",
    "            state_probability = emission_p * transition_p\n",
    "            \n",
    "            p.append(state_probability)\n",
    "        \n",
    "        # Find the tag with maximum state probability\n",
    "        pmax = max(p)\n",
    "        \n",
    "        # For unknown words the state probability will be zero\n",
    "        if pmax == 0:\n",
    "            patterns = [\n",
    "                (r'.*ing$', 'VERB'),              # gerund\n",
    "                (r'.*ed$', 'VERB'),               # past tense\n",
    "                (r'.*es$', 'VERB'),               # 3rd singular present\n",
    "                (r'.*ould$', 'VERB'),              # modals\n",
    "                (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "                (r'.*s$', 'NOUN'),                # plural nouns\n",
    "                (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "                (r'.*', 'NOUN')                    # nouns\n",
    "                ]\n",
    "            \n",
    "            regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "            \n",
    "            tags = regexp_tagger.tag(nltk.word_tokenize(word))\n",
    "            \n",
    "            state.append(tags[0][1])\n",
    "                       \n",
    "        else:\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "            \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq_model2 = Viterbi_model2(test_untagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  585.9888517856598\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "matched_model2 = [i for i,j in zip(tagged_seq_model2,test_tagged_words) if i == j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951195219123506"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model2 = len(matched_model2)/len(tagged_seq_model2)\n",
    "accuracy_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "1. The accuracy of vanilla Veterbi algorithm is 91% \n",
    "2. The accuracy of Veterbi algorithm modified to assign Mode of tags for unknown words has an accuracy of 94%.\n",
    "3. The accuracy of Veterbi algorithm modified to assign tags using RegEx/Morphology for unknown words has an accuracy of 95%.\n",
    "\n",
    "Hence, we shall use the \"Viterbi_model2\" for further prediction of the POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect Tags by Vanilla Veterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched= [i for i,j in zip(tagged_seq,test_tagged_words) if i != j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_words = set([i[0] for i in unmatched])\n",
    "len(unmatched_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect Tags post modifying Veterbi with Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_model2= [i for i,j in zip(tagged_seq_model2,test_tagged_words) if i != j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_words_model2 = set([i[0] for i in unmatched_model2])\n",
    "len(unmatched_words_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'115',\n",
       " '158,666',\n",
       " '176.1',\n",
       " '1925',\n",
       " '1934',\n",
       " '20.07',\n",
       " '26,956',\n",
       " '3.43',\n",
       " '352.7',\n",
       " '35500.64',\n",
       " '576',\n",
       " '6.53',\n",
       " '608,413',\n",
       " '62.625',\n",
       " '63.79',\n",
       " '692',\n",
       " '7.20',\n",
       " '7.84',\n",
       " '80.8',\n",
       " '81.8',\n",
       " '960',\n",
       " '967,809',\n",
       " 'Alexander',\n",
       " 'Ariail',\n",
       " 'Assets',\n",
       " 'Bennett',\n",
       " 'Buckhead',\n",
       " 'Carbide',\n",
       " 'Carnegie-Mellon',\n",
       " 'Carrier',\n",
       " 'Cartons',\n",
       " 'Cerf',\n",
       " 'Competes',\n",
       " 'Debt',\n",
       " 'Default',\n",
       " 'Destinations',\n",
       " 'Determining',\n",
       " 'Discos',\n",
       " 'Doerflinger',\n",
       " 'Drink',\n",
       " 'Dunn',\n",
       " 'Dynamics',\n",
       " 'Editorials',\n",
       " 'Emile',\n",
       " 'Foreigners',\n",
       " 'Graham',\n",
       " 'Green',\n",
       " 'Gringo',\n",
       " 'Hans',\n",
       " 'Helsinki',\n",
       " 'Henderson',\n",
       " 'Herald-American',\n",
       " 'Honolulu',\n",
       " 'Ian',\n",
       " 'Joni',\n",
       " 'Kelli',\n",
       " 'Kirkpatrick',\n",
       " 'Leningrad',\n",
       " 'Leon',\n",
       " 'Level',\n",
       " 'Lucille',\n",
       " 'Manila',\n",
       " 'McCabe',\n",
       " 'McFarlan',\n",
       " 'Metal',\n",
       " 'Mexican',\n",
       " 'Mutchin',\n",
       " 'News-American',\n",
       " 'Orlando',\n",
       " 'Performing',\n",
       " 'Phillip',\n",
       " 'Rail',\n",
       " 'Regarded',\n",
       " 'Revolution',\n",
       " 'Rock',\n",
       " 'Schaefer',\n",
       " 'Schwab',\n",
       " 'Sherwin',\n",
       " 'Skokie',\n",
       " 'Sonny',\n",
       " 'Squier',\n",
       " 'Subcontractors',\n",
       " 'Sumitomo',\n",
       " 'Terrace',\n",
       " 'Theodore',\n",
       " 'Vice',\n",
       " 'Worksheets',\n",
       " 'Yasuda',\n",
       " 'abating',\n",
       " 'aces',\n",
       " 'adapting',\n",
       " 'aids',\n",
       " 'amended',\n",
       " 'authorizes',\n",
       " 'authorizing',\n",
       " 'automation',\n",
       " 'autos',\n",
       " 'bars',\n",
       " 'blender',\n",
       " 'brand',\n",
       " 'chairs',\n",
       " 'challenging',\n",
       " 'close-up',\n",
       " 'codified',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'communication',\n",
       " 'companion',\n",
       " 'concedes',\n",
       " 'copied',\n",
       " 'counterattack',\n",
       " 'crashing',\n",
       " 'dawn',\n",
       " 'dealing',\n",
       " 'designated',\n",
       " 'destination',\n",
       " 'discontinuing',\n",
       " 'displays',\n",
       " 'distributes',\n",
       " 'dominates',\n",
       " 'driver',\n",
       " 'echoed',\n",
       " 'enclosed',\n",
       " 'enjoyed',\n",
       " 'entering',\n",
       " 'equal-opportunity',\n",
       " 'everybody',\n",
       " 'excited',\n",
       " 'folded',\n",
       " 'gamut',\n",
       " 'garden-variety',\n",
       " 'genie',\n",
       " 'headcount-control',\n",
       " 'housewife',\n",
       " 'indictment',\n",
       " 'infringed',\n",
       " 'infusion',\n",
       " 'integrated',\n",
       " 'invention',\n",
       " 'iota',\n",
       " 'jolts',\n",
       " 'kit',\n",
       " 'lapses',\n",
       " 'legislators',\n",
       " 'literature',\n",
       " 'livelihood',\n",
       " 'lookee-loos',\n",
       " 'materialized',\n",
       " 'mentioned',\n",
       " 'microphone',\n",
       " 'mid-1990s',\n",
       " 'ministers',\n",
       " 'mothers',\n",
       " 'net',\n",
       " 'off',\n",
       " 'one-fifth',\n",
       " 'onslaught',\n",
       " 'opinions',\n",
       " 'ordeal',\n",
       " 'oversight',\n",
       " 'overstated',\n",
       " 'overused',\n",
       " 'plane',\n",
       " 'precedes',\n",
       " 'predicated',\n",
       " 'procurement',\n",
       " 'produces',\n",
       " 'productivity',\n",
       " 'psychiatrist',\n",
       " 'recalling',\n",
       " 'recruited',\n",
       " 'redeeming',\n",
       " 'retiring',\n",
       " 'seconds',\n",
       " 'self-esteem',\n",
       " 'shadows',\n",
       " 'shaping',\n",
       " 'shipyards',\n",
       " 'skepticism',\n",
       " 'slowdowns',\n",
       " 'sticker-shock',\n",
       " 'stirrings',\n",
       " 'stock-price',\n",
       " 'stream',\n",
       " 'striving',\n",
       " 'swift',\n",
       " 'talked',\n",
       " 'telephone-information',\n",
       " 'tire-kickers',\n",
       " 'transporting',\n",
       " 'troop',\n",
       " 'twin-jet',\n",
       " 'workforce',\n",
       " 'wrestling'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words which got predicted correctly post mophological changes Veterbi\n",
    "unmatched_words.difference(unmatched_words_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "The number of incorrect tags reduced from 399 to 245 post modifiations to Vanilla Veterbi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting POS tags for the Test Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Test_sentences.txt\") as f:\n",
    "    contents = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [word_tokenize(i.rstrip(\"\\n\")) for i in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging using original Vetribi\n",
    "start = time.time()\n",
    "tagged_seq_vanilla = [Viterbi(words) for words in sents]\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Android', 'ADJ'),\n",
       "  ('is', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('mobile', 'ADJ'),\n",
       "  ('operating', 'NOUN'),\n",
       "  ('system', 'NOUN'),\n",
       "  ('developed', 'VERB'),\n",
       "  ('by', 'ADP'),\n",
       "  ('Google', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Android', 'ADJ'),\n",
       "  ('has', 'VERB'),\n",
       "  ('been', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('best-selling', 'ADJ'),\n",
       "  ('OS', 'ADJ'),\n",
       "  ('worldwide', 'ADJ'),\n",
       "  ('on', 'ADP'),\n",
       "  ('smartphones', 'ADJ'),\n",
       "  ('since', 'ADP'),\n",
       "  ('2011', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('on', 'ADP'),\n",
       "  ('tablets', 'NOUN'),\n",
       "  ('since', 'ADP'),\n",
       "  ('2013', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Google', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('Twitter', 'ADJ'),\n",
       "  ('made', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('deal', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('2015', 'ADJ'),\n",
       "  ('that', 'ADP'),\n",
       "  ('gave', 'VERB'),\n",
       "  ('Google', 'ADJ'),\n",
       "  ('access', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('Twitter', 'ADJ'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('firehose', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Twitter', 'ADJ'),\n",
       "  ('is', 'VERB'),\n",
       "  ('an', 'DET'),\n",
       "  ('online', 'ADJ'),\n",
       "  ('news', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('social', 'ADJ'),\n",
       "  ('networking', 'NOUN'),\n",
       "  ('service', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('which', 'DET'),\n",
       "  ('users', 'NOUN'),\n",
       "  ('post', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('interact', 'ADJ'),\n",
       "  ('with', 'ADP'),\n",
       "  ('messages', 'ADJ'),\n",
       "  ('known', 'VERB'),\n",
       "  ('as', 'ADP'),\n",
       "  ('tweets', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Before', 'ADP'),\n",
       "  ('entering', 'ADJ'),\n",
       "  ('politics', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('Donald', 'NOUN'),\n",
       "  ('Trump', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('domineering', 'ADJ'),\n",
       "  ('businessman', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('a', 'DET'),\n",
       "  ('television', 'NOUN'),\n",
       "  ('personality', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('2018', 'ADJ'),\n",
       "  ('FIFA', 'ADJ'),\n",
       "  ('World', 'NOUN'),\n",
       "  ('Cup', 'ADJ'),\n",
       "  ('is', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('21st', 'ADJ'),\n",
       "  ('FIFA', 'ADJ'),\n",
       "  ('World', 'NOUN'),\n",
       "  ('Cup', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('an', 'DET'),\n",
       "  ('international', 'ADJ'),\n",
       "  ('football', 'NOUN'),\n",
       "  ('tournament', 'ADJ'),\n",
       "  ('contested', 'ADJ'),\n",
       "  ('once', 'ADV'),\n",
       "  ('every', 'DET'),\n",
       "  ('four', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('first', 'ADJ'),\n",
       "  ('World', 'NOUN'),\n",
       "  ('Cup', 'ADJ'),\n",
       "  ('to', 'PRT'),\n",
       "  ('be', 'VERB'),\n",
       "  ('held', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('Eastern', 'NOUN'),\n",
       "  ('Europe', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('11th', 'ADJ'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('that', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('has', 'VERB'),\n",
       "  ('been', 'VERB'),\n",
       "  ('held', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('Europe', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Show', 'NOUN'),\n",
       "  ('me', 'PRON'),\n",
       "  ('the', 'DET'),\n",
       "  ('cheapest', 'ADJ'),\n",
       "  ('round', 'NOUN'),\n",
       "  ('trips', 'ADJ'),\n",
       "  ('from', 'ADP'),\n",
       "  ('Dallas', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('Atlanta', 'NOUN')],\n",
       " [('I', 'PRON'),\n",
       "  ('would', 'VERB'),\n",
       "  ('like', 'ADP'),\n",
       "  ('to', 'PRT'),\n",
       "  ('see', 'VERB'),\n",
       "  ('flights', 'NOUN'),\n",
       "  ('from', 'ADP'),\n",
       "  ('Denver', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('Philadelphia', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Show', 'NOUN'),\n",
       "  ('me', 'PRON'),\n",
       "  ('the', 'DET'),\n",
       "  ('price', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('flights', 'NOUN'),\n",
       "  ('leaving', 'VERB'),\n",
       "  ('Atlanta', 'NOUN'),\n",
       "  ('at', 'ADP'),\n",
       "  ('about', 'ADP'),\n",
       "  ('3', 'NUM'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('afternoon', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('arriving', 'ADJ'),\n",
       "  ('in', 'ADP'),\n",
       "  ('San', 'NOUN'),\n",
       "  ('Francisco', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('NASA', 'ADJ'),\n",
       "  ('invited', 'ADJ'),\n",
       "  ('social', 'ADJ'),\n",
       "  ('media', 'NOUN'),\n",
       "  ('users', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('experience', 'NOUN'),\n",
       "  ('the', 'DET'),\n",
       "  ('launch', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('ICESAT-2', 'ADJ'),\n",
       "  ('Satellite', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_seq_vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "It can be seen that vanilla Veterbi algorithm is not able to predict the unknow words correctly from the sample text. FOllowing are somre of the examples noticed:\n",
    "1. Andriod, Google and Twitter are tagged as Adjectives. These should have been marked as Noun.\n",
    "2. Numeric figures like 2011 are marked as Adjective. These should have been marked as Number.\n",
    "3. Words like \"domineering\" etc are marked as Adjective. This shoud have been makred as verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging with modified Veterbi with Morphology\n",
    "start = time.time()\n",
    "tagged_seq_verify = [Viterbi_model2(words) for words in sents]\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')], [('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')], [('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.')], [('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'VERB'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.')], [('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.')], [('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')], [('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.')], [('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN')], [('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.')], [('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.')], [('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')], [], [], []]\n",
      "18.64898133277893\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq_verify)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "It can be noticed that unkwown words like Google, Android, domineering and numeric values like 2011 etc which were marked as Adjective are not correctly tagged as Noun and Verbs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
